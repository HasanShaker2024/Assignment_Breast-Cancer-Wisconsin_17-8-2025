{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Breast Cancer Wisconsin Dataset\n",
        "Taregt: Improve Accuracy - Search (Regularization, Batch Normalization, and validation_split vs validation_data)\n",
        "\n",
        "- Hasan Samir Hasan\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial Model Summary:\n",
        "#### Model Configuration:\n",
        "* 3 hidden layers with ReLU (Neurons: 32,16,8).\n",
        "* 1 Dropout (0.3) Layer\n",
        "* 1 output layer with Sigmoid for binary classification.\n",
        "* Binary Crossentropy loss + SGD optimizer.\n",
        "* epochs=30, batch_size=32\n",
        "* Validation split using test data\n",
        "#### Results: \n",
        "* accuracy: 0.9294\n",
        "* loss: 0.1790 \n",
        "* val_accuracy: 0.9561\n",
        "* val_loss: 0.1302\n",
        "\n",
        "- The Model results are not good and not stable where in every execution gives different results.\n",
        "##### After Adding Seed, the results become reproducibil and gives same results every execution.\n",
        "* accuracy: 0.9520\n",
        "* loss: 0.1852\n",
        "* val_accuracy: 0.9649\n",
        "* val_loss: 0.0936 \n",
        "\n",
        "But Still the model has not good accuracy.\n",
        "## Some Trials:\n",
        "- epochs=100, batch_size=32 >> accuracy: 0.9607 - loss: 0.1266 - val_accuracy: 0.9825 - val_loss: 0.0741 (Underfitting).\n",
        "\n",
        "- epochs=120, batch_size=32 >> accuracy: 0.9713 - loss: 0.1225 - val_accuracy: 0.9825 - val_loss: 0.0717 (Improved but still Underfitting).\n",
        "\n",
        "- epochs=120, batch_size=64 >> accuracy: 0.9507 - loss: 0.1320 - val_accuracy: 0.9737 - val_loss: 0.0871 (Become worse).\n",
        "\n",
        "- epochs=120, batch_size=16 >> accuracy: 0.9633 - loss: 0.0918 - val_accuracy: 0.9737 - val_loss: 0.0757 (Still is not good enough).\n",
        "\n",
        "- epochs=264, batch_size=32 >> accuracy: 0.9775 - loss: 0.0729 - val_accuracy: 0.9825 - val_loss: 0.0749 (Improved but still Underfitting)\n",
        "\n",
        "# The Final Configuration: \n",
        "#### Model Configuration:\n",
        "* 3 hidden layers with ReLU (Neurons: 32,16,8) with Regularization (kernel_regularizer=regularizers.l2(0.01)).\n",
        "* 1 Dropout (0.3) Layer\n",
        "* 1 output layer with Sigmoid for binary classification.\n",
        "* Binary Crossentropy loss + adam optimizer.\n",
        "* epochs=256, batch_size=32\n",
        "* Validation split using test data\n",
        "* accuracy:0.9821 - loss: 0.0924 - val_accuracy: 0.9825 - val_loss: 0.1110\n",
        "\n",
        "##### Modifying Dropout from 0.3 to 0.2\n",
        "* accuracy: 0.9876 - loss: 0.0822 - val_accuracy: 0.9825 - val_loss: 0.1055"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-nuRJH00pc59"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.layers import Dense, Input, Activation\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WG5tvOWbprvm"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "W2yNeQX_pth0",
        "outputId": "d669142a-c539-47bd-9776-97049c4e474c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gf_beotpuKZ",
        "outputId": "c12b243f-2327-4226-8268-5dcead7b15f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            " 32  Unnamed: 32              0 non-null      float64\n",
            "dtypes: float64(31), int64(1), object(1)\n",
            "memory usage: 146.8+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9dzDYxBpyok",
        "outputId": "9476987d-36bb-42f8-808b-1a208d0a24a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
              "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
              "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
              "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
              "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
              "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
              "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
              "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
              "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tL3JYbdap7w4"
      },
      "outputs": [],
      "source": [
        "df.drop(['id'], axis = 1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DR9hT-mjqFEu"
      },
      "outputs": [],
      "source": [
        "df.drop(['Unnamed: 32'], axis = 1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1DMFTwJqGZm",
        "outputId": "f6f66552-83ce-4689-db75-e3c5517af0fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
              "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
              "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
              "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
              "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
              "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
              "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
              "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
              "       'symmetry_worst', 'fractal_dimension_worst'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7m7Ax9ULqHiq",
        "outputId": "8a09eae5-8a7f-44f4-91e3-360d9076c5b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "diagnosis                  0\n",
              "radius_mean                0\n",
              "texture_mean               0\n",
              "perimeter_mean             0\n",
              "area_mean                  0\n",
              "smoothness_mean            0\n",
              "compactness_mean           0\n",
              "concavity_mean             0\n",
              "concave points_mean        0\n",
              "symmetry_mean              0\n",
              "fractal_dimension_mean     0\n",
              "radius_se                  0\n",
              "texture_se                 0\n",
              "perimeter_se               0\n",
              "area_se                    0\n",
              "smoothness_se              0\n",
              "compactness_se             0\n",
              "concavity_se               0\n",
              "concave points_se          0\n",
              "symmetry_se                0\n",
              "fractal_dimension_se       0\n",
              "radius_worst               0\n",
              "texture_worst              0\n",
              "perimeter_worst            0\n",
              "area_worst                 0\n",
              "smoothness_worst           0\n",
              "compactness_worst          0\n",
              "concavity_worst            0\n",
              "concave points_worst       0\n",
              "symmetry_worst             0\n",
              "fractal_dimension_worst    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "qQxSNjBcqKEk",
        "outputId": "8bcb4f7e-39be-4122-f908-0b876286d918"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "diagnosis\n",
              "B    357\n",
              "M    212\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['diagnosis'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xSh8VZmlqXT7"
      },
      "outputs": [],
      "source": [
        "df['diagnosis'] = df['diagnosis'].map({'M' : 1 , 'B' : 0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcUFNzhHqxc6",
        "outputId": "93c7aff4-0607-4b02-f965-7214c42f173f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0], dtype=int64)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['diagnosis'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1xbXOwYdqzfO"
      },
      "outputs": [],
      "source": [
        "x = df.drop(columns=['diagnosis'])\n",
        "y = df['diagnosis']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "W6IzvK4Oq9y4"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTVnGpI6rIX6",
        "outputId": "ceced5b4-7169-4dd8-a88b-0e7ec30cdeed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(455, 30)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXXgcqnBrL_7",
        "outputId": "ef836f35-98fe-4b12-ce2b-93a8ec44efe6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(114, 30)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Dhf3hzirNUN",
        "outputId": "f888c0ac-15e4-4267-b5a1-065c08325bd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(455,)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKa4TkserRAq",
        "outputId": "5f613032-b141-4a5f-ee3c-e6a24cff785f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(114,)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EEqj6Ubgrbpk"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jbdtV_GDrc1i"
      },
      "outputs": [],
      "source": [
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uX0L6eXOsC5s"
      },
      "outputs": [],
      "source": [
        "# Input Layer\n",
        "inputs = Input(shape=(x_train.shape[1],))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2Z1txa4KsVDt"
      },
      "outputs": [],
      "source": [
        "# Fully Connected Layers#kernel_regularizer=regularizers.l2(0.01)\n",
        "x1 = Dense(32, activation='relu',kernel_regularizer=regularizers.l2(0.01))(inputs)\n",
        "x2 = Dense(16,  activation='relu',kernel_regularizer=regularizers.l2(0.01))(x1)\n",
        "x3 = Dropout(0.2)(x2)\n",
        "x4 = Dense(8, activation='relu',kernel_regularizer=regularizers.l2(0.01))(x3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "a7Acbh8XtSad"
      },
      "outputs": [],
      "source": [
        "outputs = Dense(1, activation='sigmoid')(x4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "yJWWLsRDuQS4"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "pn7ny5Jtue0J",
        "outputId": "08a4bf81-b057-4d6b-ff73-30cec1623cf4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">992</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m992\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,665</span> (6.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,665\u001b[0m (6.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,665</span> (6.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,665\u001b[0m (6.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "j_NXcW7puhTP"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IoClIhguyg6",
        "outputId": "26a10462-d85d-4414-b0ce-3c5640139784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 156ms/step - accuracy: 0.7160 - loss: 1.1901 - val_accuracy: 0.8947 - val_loss: 0.9652\n",
            "Epoch 2/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8383 - loss: 1.0116 - val_accuracy: 0.9474 - val_loss: 0.8524\n",
            "Epoch 3/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9160 - loss: 0.8887 - val_accuracy: 0.9561 - val_loss: 0.7702\n",
            "Epoch 4/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9053 - loss: 0.8432 - val_accuracy: 0.9649 - val_loss: 0.7072\n",
            "Epoch 5/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9430 - loss: 0.7826 - val_accuracy: 0.9737 - val_loss: 0.6578\n",
            "Epoch 6/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9544 - loss: 0.7167 - val_accuracy: 0.9649 - val_loss: 0.6196\n",
            "Epoch 7/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9617 - loss: 0.6951 - val_accuracy: 0.9649 - val_loss: 0.5887\n",
            "Epoch 8/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9577 - loss: 0.6495 - val_accuracy: 0.9649 - val_loss: 0.5618\n",
            "Epoch 9/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9613 - loss: 0.5937 - val_accuracy: 0.9737 - val_loss: 0.5357\n",
            "Epoch 10/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9707 - loss: 0.5860 - val_accuracy: 0.9737 - val_loss: 0.5125\n",
            "Epoch 11/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9587 - loss: 0.5575 - val_accuracy: 0.9825 - val_loss: 0.4922\n",
            "Epoch 12/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9697 - loss: 0.5351 - val_accuracy: 0.9649 - val_loss: 0.4729\n",
            "Epoch 13/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9721 - loss: 0.5030 - val_accuracy: 0.9737 - val_loss: 0.4549\n",
            "Epoch 14/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9695 - loss: 0.4975 - val_accuracy: 0.9737 - val_loss: 0.4375\n",
            "Epoch 15/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9744 - loss: 0.4653 - val_accuracy: 0.9737 - val_loss: 0.4203\n",
            "Epoch 16/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9710 - loss: 0.4586 - val_accuracy: 0.9737 - val_loss: 0.4052\n",
            "Epoch 17/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9786 - loss: 0.4273 - val_accuracy: 0.9649 - val_loss: 0.3899\n",
            "Epoch 18/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9744 - loss: 0.4292 - val_accuracy: 0.9737 - val_loss: 0.3747\n",
            "Epoch 19/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9774 - loss: 0.3979 - val_accuracy: 0.9737 - val_loss: 0.3608\n",
            "Epoch 20/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9779 - loss: 0.3799 - val_accuracy: 0.9737 - val_loss: 0.3472\n",
            "Epoch 21/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9763 - loss: 0.3706 - val_accuracy: 0.9737 - val_loss: 0.3342\n",
            "Epoch 22/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9661 - loss: 0.3525 - val_accuracy: 0.9737 - val_loss: 0.3224\n",
            "Epoch 23/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9763 - loss: 0.3472 - val_accuracy: 0.9737 - val_loss: 0.3112\n",
            "Epoch 24/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9781 - loss: 0.3394 - val_accuracy: 0.9737 - val_loss: 0.3005\n",
            "Epoch 25/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9745 - loss: 0.3286 - val_accuracy: 0.9737 - val_loss: 0.2902\n",
            "Epoch 26/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9738 - loss: 0.3113 - val_accuracy: 0.9737 - val_loss: 0.2807\n",
            "Epoch 27/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9765 - loss: 0.2976 - val_accuracy: 0.9649 - val_loss: 0.2728\n",
            "Epoch 28/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9774 - loss: 0.2854 - val_accuracy: 0.9737 - val_loss: 0.2622\n",
            "Epoch 29/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9751 - loss: 0.2879 - val_accuracy: 0.9825 - val_loss: 0.2521\n",
            "Epoch 30/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9812 - loss: 0.2701 - val_accuracy: 0.9825 - val_loss: 0.2439\n",
            "Epoch 31/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9691 - loss: 0.2628 - val_accuracy: 0.9825 - val_loss: 0.2364\n",
            "Epoch 32/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9756 - loss: 0.2604 - val_accuracy: 0.9649 - val_loss: 0.2321\n",
            "Epoch 33/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9821 - loss: 0.2454 - val_accuracy: 0.9825 - val_loss: 0.2233\n",
            "Epoch 34/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9777 - loss: 0.2342 - val_accuracy: 0.9825 - val_loss: 0.2164\n",
            "Epoch 35/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9781 - loss: 0.2393 - val_accuracy: 0.9825 - val_loss: 0.2108\n",
            "Epoch 36/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9821 - loss: 0.2394 - val_accuracy: 0.9825 - val_loss: 0.2054\n",
            "Epoch 37/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9812 - loss: 0.2141 - val_accuracy: 0.9825 - val_loss: 0.1999\n",
            "Epoch 38/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9804 - loss: 0.2148 - val_accuracy: 0.9825 - val_loss: 0.1952\n",
            "Epoch 39/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9750 - loss: 0.2183 - val_accuracy: 0.9825 - val_loss: 0.1904\n",
            "Epoch 40/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9727 - loss: 0.2089 - val_accuracy: 0.9825 - val_loss: 0.1867\n",
            "Epoch 41/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9804 - loss: 0.2103 - val_accuracy: 0.9825 - val_loss: 0.1827\n",
            "Epoch 42/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9821 - loss: 0.1978 - val_accuracy: 0.9737 - val_loss: 0.1792\n",
            "Epoch 43/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9799 - loss: 0.1914 - val_accuracy: 0.9737 - val_loss: 0.1757\n",
            "Epoch 44/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9762 - loss: 0.1884 - val_accuracy: 0.9825 - val_loss: 0.1724\n",
            "Epoch 45/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9804 - loss: 0.1842 - val_accuracy: 0.9825 - val_loss: 0.1693\n",
            "Epoch 46/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9812 - loss: 0.1631 - val_accuracy: 0.9825 - val_loss: 0.1651\n",
            "Epoch 47/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9788 - loss: 0.1855 - val_accuracy: 0.9825 - val_loss: 0.1628\n",
            "Epoch 48/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9813 - loss: 0.1851 - val_accuracy: 0.9825 - val_loss: 0.1597\n",
            "Epoch 49/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9812 - loss: 0.1747 - val_accuracy: 0.9825 - val_loss: 0.1573\n",
            "Epoch 50/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9821 - loss: 0.1652 - val_accuracy: 0.9825 - val_loss: 0.1545\n",
            "Epoch 51/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9812 - loss: 0.1752 - val_accuracy: 0.9825 - val_loss: 0.1527\n",
            "Epoch 52/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9774 - loss: 0.1802 - val_accuracy: 0.9825 - val_loss: 0.1512\n",
            "Epoch 53/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9800 - loss: 0.1637 - val_accuracy: 0.9825 - val_loss: 0.1503\n",
            "Epoch 54/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9799 - loss: 0.1655 - val_accuracy: 0.9825 - val_loss: 0.1496\n",
            "Epoch 55/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9812 - loss: 0.1572 - val_accuracy: 0.9825 - val_loss: 0.1470\n",
            "Epoch 56/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9812 - loss: 0.1605 - val_accuracy: 0.9825 - val_loss: 0.1448\n",
            "Epoch 57/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9765 - loss: 0.1620 - val_accuracy: 0.9825 - val_loss: 0.1433\n",
            "Epoch 58/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9821 - loss: 0.1562 - val_accuracy: 0.9825 - val_loss: 0.1407\n",
            "Epoch 59/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9858 - loss: 0.1448 - val_accuracy: 0.9737 - val_loss: 0.1389\n",
            "Epoch 60/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9804 - loss: 0.1495 - val_accuracy: 0.9737 - val_loss: 0.1384\n",
            "Epoch 61/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9755 - loss: 0.1500 - val_accuracy: 0.9825 - val_loss: 0.1366\n",
            "Epoch 62/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9802 - loss: 0.1567 - val_accuracy: 0.9825 - val_loss: 0.1369\n",
            "Epoch 63/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9755 - loss: 0.1595 - val_accuracy: 0.9825 - val_loss: 0.1378\n",
            "Epoch 64/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9821 - loss: 0.1513 - val_accuracy: 0.9825 - val_loss: 0.1357\n",
            "Epoch 65/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9812 - loss: 0.1308 - val_accuracy: 0.9825 - val_loss: 0.1315\n",
            "Epoch 66/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9821 - loss: 0.1477 - val_accuracy: 0.9825 - val_loss: 0.1318\n",
            "Epoch 67/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9821 - loss: 0.1450 - val_accuracy: 0.9825 - val_loss: 0.1314\n",
            "Epoch 68/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9804 - loss: 0.1405 - val_accuracy: 0.9825 - val_loss: 0.1303\n",
            "Epoch 69/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9777 - loss: 0.1482 - val_accuracy: 0.9737 - val_loss: 0.1302\n",
            "Epoch 70/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9804 - loss: 0.1472 - val_accuracy: 0.9825 - val_loss: 0.1287\n",
            "Epoch 71/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9812 - loss: 0.1370 - val_accuracy: 0.9825 - val_loss: 0.1276\n",
            "Epoch 72/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9812 - loss: 0.1386 - val_accuracy: 0.9737 - val_loss: 0.1283\n",
            "Epoch 73/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9804 - loss: 0.1316 - val_accuracy: 0.9737 - val_loss: 0.1276\n",
            "Epoch 74/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9804 - loss: 0.1401 - val_accuracy: 0.9825 - val_loss: 0.1259\n",
            "Epoch 75/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9808 - loss: 0.1273 - val_accuracy: 0.9825 - val_loss: 0.1252\n",
            "Epoch 76/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9790 - loss: 0.1435 - val_accuracy: 0.9825 - val_loss: 0.1259\n",
            "Epoch 77/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9804 - loss: 0.1369 - val_accuracy: 0.9825 - val_loss: 0.1252\n",
            "Epoch 78/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9745 - loss: 0.1346 - val_accuracy: 0.9825 - val_loss: 0.1226\n",
            "Epoch 79/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9734 - loss: 0.1393 - val_accuracy: 0.9825 - val_loss: 0.1234\n",
            "Epoch 80/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9783 - loss: 0.1315 - val_accuracy: 0.9912 - val_loss: 0.1230\n",
            "Epoch 81/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9821 - loss: 0.1448 - val_accuracy: 0.9912 - val_loss: 0.1222\n",
            "Epoch 82/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9821 - loss: 0.1295 - val_accuracy: 0.9825 - val_loss: 0.1237\n",
            "Epoch 83/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9808 - loss: 0.1269 - val_accuracy: 0.9737 - val_loss: 0.1231\n",
            "Epoch 84/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9784 - loss: 0.1244 - val_accuracy: 0.9825 - val_loss: 0.1220\n",
            "Epoch 85/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9813 - loss: 0.1281 - val_accuracy: 0.9825 - val_loss: 0.1212\n",
            "Epoch 86/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9804 - loss: 0.1313 - val_accuracy: 0.9825 - val_loss: 0.1221\n",
            "Epoch 87/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9821 - loss: 0.1184 - val_accuracy: 0.9825 - val_loss: 0.1205\n",
            "Epoch 88/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9812 - loss: 0.1221 - val_accuracy: 0.9825 - val_loss: 0.1192\n",
            "Epoch 89/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9860 - loss: 0.1209 - val_accuracy: 0.9825 - val_loss: 0.1185\n",
            "Epoch 90/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9804 - loss: 0.1279 - val_accuracy: 0.9825 - val_loss: 0.1186\n",
            "Epoch 91/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9800 - loss: 0.1323 - val_accuracy: 0.9825 - val_loss: 0.1185\n",
            "Epoch 92/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9812 - loss: 0.1296 - val_accuracy: 0.9825 - val_loss: 0.1197\n",
            "Epoch 93/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.9821 - loss: 0.1253 - val_accuracy: 0.9825 - val_loss: 0.1187\n",
            "Epoch 94/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - accuracy: 0.9821 - loss: 0.1262 - val_accuracy: 0.9825 - val_loss: 0.1182\n",
            "Epoch 95/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9804 - loss: 0.1295 - val_accuracy: 0.9825 - val_loss: 0.1173\n",
            "Epoch 96/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9821 - loss: 0.1171 - val_accuracy: 0.9825 - val_loss: 0.1167\n",
            "Epoch 97/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9812 - loss: 0.1219 - val_accuracy: 0.9825 - val_loss: 0.1182\n",
            "Epoch 98/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9781 - loss: 0.1338 - val_accuracy: 0.9825 - val_loss: 0.1196\n",
            "Epoch 99/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9813 - loss: 0.1190 - val_accuracy: 0.9825 - val_loss: 0.1177\n",
            "Epoch 100/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9871 - loss: 0.1157 - val_accuracy: 0.9912 - val_loss: 0.1140\n",
            "Epoch 101/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9745 - loss: 0.1246 - val_accuracy: 0.9912 - val_loss: 0.1142\n",
            "Epoch 102/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9817 - loss: 0.1242 - val_accuracy: 0.9825 - val_loss: 0.1150\n",
            "Epoch 103/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9821 - loss: 0.1106 - val_accuracy: 0.9825 - val_loss: 0.1150\n",
            "Epoch 104/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9812 - loss: 0.1217 - val_accuracy: 0.9825 - val_loss: 0.1157\n",
            "Epoch 105/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9821 - loss: 0.1236 - val_accuracy: 0.9825 - val_loss: 0.1151\n",
            "Epoch 106/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9821 - loss: 0.1239 - val_accuracy: 0.9825 - val_loss: 0.1143\n",
            "Epoch 107/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9812 - loss: 0.1183 - val_accuracy: 0.9825 - val_loss: 0.1141\n",
            "Epoch 108/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.9812 - loss: 0.1146 - val_accuracy: 0.9825 - val_loss: 0.1138\n",
            "Epoch 109/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.9821 - loss: 0.1290 - val_accuracy: 0.9825 - val_loss: 0.1141\n",
            "Epoch 110/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9821 - loss: 0.1290 - val_accuracy: 0.9912 - val_loss: 0.1159\n",
            "Epoch 111/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9812 - loss: 0.1119 - val_accuracy: 0.9825 - val_loss: 0.1138\n",
            "Epoch 112/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9707 - loss: 0.1246 - val_accuracy: 0.9825 - val_loss: 0.1135\n",
            "Epoch 113/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9887 - loss: 0.1157 - val_accuracy: 0.9825 - val_loss: 0.1127\n",
            "Epoch 114/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9821 - loss: 0.1217 - val_accuracy: 0.9912 - val_loss: 0.1125\n",
            "Epoch 115/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9813 - loss: 0.1196 - val_accuracy: 0.9825 - val_loss: 0.1121\n",
            "Epoch 116/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9770 - loss: 0.1163 - val_accuracy: 0.9825 - val_loss: 0.1113\n",
            "Epoch 117/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9813 - loss: 0.1233 - val_accuracy: 0.9825 - val_loss: 0.1113\n",
            "Epoch 118/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9821 - loss: 0.1165 - val_accuracy: 0.9825 - val_loss: 0.1114\n",
            "Epoch 119/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9821 - loss: 0.1271 - val_accuracy: 0.9912 - val_loss: 0.1126\n",
            "Epoch 120/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9812 - loss: 0.1166 - val_accuracy: 0.9825 - val_loss: 0.1120\n",
            "Epoch 121/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9808 - loss: 0.1049 - val_accuracy: 0.9825 - val_loss: 0.1113\n",
            "Epoch 122/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9715 - loss: 0.1203 - val_accuracy: 0.9825 - val_loss: 0.1123\n",
            "Epoch 123/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9813 - loss: 0.1112 - val_accuracy: 0.9825 - val_loss: 0.1120\n",
            "Epoch 124/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9821 - loss: 0.1090 - val_accuracy: 0.9825 - val_loss: 0.1129\n",
            "Epoch 125/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9812 - loss: 0.1093 - val_accuracy: 0.9825 - val_loss: 0.1109\n",
            "Epoch 126/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9830 - loss: 0.1173 - val_accuracy: 0.9912 - val_loss: 0.1091\n",
            "Epoch 127/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9813 - loss: 0.1114 - val_accuracy: 0.9825 - val_loss: 0.1094\n",
            "Epoch 128/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9821 - loss: 0.1118 - val_accuracy: 0.9825 - val_loss: 0.1119\n",
            "Epoch 129/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9747 - loss: 0.1069 - val_accuracy: 0.9825 - val_loss: 0.1132\n",
            "Epoch 130/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9804 - loss: 0.1033 - val_accuracy: 0.9825 - val_loss: 0.1106\n",
            "Epoch 131/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9775 - loss: 0.1089 - val_accuracy: 0.9825 - val_loss: 0.1083\n",
            "Epoch 132/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9774 - loss: 0.1135 - val_accuracy: 0.9825 - val_loss: 0.1098\n",
            "Epoch 133/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9808 - loss: 0.1122 - val_accuracy: 0.9825 - val_loss: 0.1122\n",
            "Epoch 134/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9821 - loss: 0.0976 - val_accuracy: 0.9825 - val_loss: 0.1118\n",
            "Epoch 135/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9821 - loss: 0.1046 - val_accuracy: 0.9825 - val_loss: 0.1128\n",
            "Epoch 136/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9858 - loss: 0.1049 - val_accuracy: 0.9825 - val_loss: 0.1114\n",
            "Epoch 137/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9802 - loss: 0.1054 - val_accuracy: 0.9825 - val_loss: 0.1116\n",
            "Epoch 138/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9812 - loss: 0.0909 - val_accuracy: 0.9825 - val_loss: 0.1116\n",
            "Epoch 139/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9800 - loss: 0.0991 - val_accuracy: 0.9825 - val_loss: 0.1104\n",
            "Epoch 140/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9804 - loss: 0.1094 - val_accuracy: 0.9825 - val_loss: 0.1110\n",
            "Epoch 141/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9821 - loss: 0.0996 - val_accuracy: 0.9825 - val_loss: 0.1111\n",
            "Epoch 142/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9840 - loss: 0.0976 - val_accuracy: 0.9825 - val_loss: 0.1107\n",
            "Epoch 143/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9821 - loss: 0.1030 - val_accuracy: 0.9825 - val_loss: 0.1101\n",
            "Epoch 144/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9781 - loss: 0.1086 - val_accuracy: 0.9825 - val_loss: 0.1112\n",
            "Epoch 145/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9741 - loss: 0.1036 - val_accuracy: 0.9825 - val_loss: 0.1115\n",
            "Epoch 146/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9755 - loss: 0.0982 - val_accuracy: 0.9825 - val_loss: 0.1116\n",
            "Epoch 147/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9804 - loss: 0.1147 - val_accuracy: 0.9825 - val_loss: 0.1129\n",
            "Epoch 148/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9745 - loss: 0.1041 - val_accuracy: 0.9825 - val_loss: 0.1137\n",
            "Epoch 149/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9804 - loss: 0.1036 - val_accuracy: 0.9825 - val_loss: 0.1118\n",
            "Epoch 150/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9821 - loss: 0.1136 - val_accuracy: 0.9825 - val_loss: 0.1098\n",
            "Epoch 151/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9802 - loss: 0.1097 - val_accuracy: 0.9825 - val_loss: 0.1109\n",
            "Epoch 152/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9755 - loss: 0.1147 - val_accuracy: 0.9825 - val_loss: 0.1130\n",
            "Epoch 153/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9751 - loss: 0.1051 - val_accuracy: 0.9825 - val_loss: 0.1132\n",
            "Epoch 154/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9786 - loss: 0.1060 - val_accuracy: 0.9825 - val_loss: 0.1133\n",
            "Epoch 155/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9821 - loss: 0.1002 - val_accuracy: 0.9825 - val_loss: 0.1120\n",
            "Epoch 156/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9762 - loss: 0.0966 - val_accuracy: 0.9825 - val_loss: 0.1102\n",
            "Epoch 157/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9887 - loss: 0.0924 - val_accuracy: 0.9825 - val_loss: 0.1093\n",
            "Epoch 158/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9813 - loss: 0.1066 - val_accuracy: 0.9825 - val_loss: 0.1096\n",
            "Epoch 159/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9812 - loss: 0.0916 - val_accuracy: 0.9825 - val_loss: 0.1095\n",
            "Epoch 160/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9821 - loss: 0.1081 - val_accuracy: 0.9825 - val_loss: 0.1101\n",
            "Epoch 161/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9755 - loss: 0.0969 - val_accuracy: 0.9825 - val_loss: 0.1112\n",
            "Epoch 162/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9808 - loss: 0.0940 - val_accuracy: 0.9825 - val_loss: 0.1113\n",
            "Epoch 163/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9790 - loss: 0.1030 - val_accuracy: 0.9825 - val_loss: 0.1110\n",
            "Epoch 164/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9743 - loss: 0.1045 - val_accuracy: 0.9825 - val_loss: 0.1099\n",
            "Epoch 165/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.9821 - loss: 0.0947 - val_accuracy: 0.9825 - val_loss: 0.1109\n",
            "Epoch 166/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9791 - loss: 0.1072 - val_accuracy: 0.9737 - val_loss: 0.1122\n",
            "Epoch 167/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9821 - loss: 0.0927 - val_accuracy: 0.9825 - val_loss: 0.1099\n",
            "Epoch 168/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9799 - loss: 0.0911 - val_accuracy: 0.9825 - val_loss: 0.1086\n",
            "Epoch 169/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9821 - loss: 0.0950 - val_accuracy: 0.9825 - val_loss: 0.1077\n",
            "Epoch 170/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9809 - loss: 0.0973 - val_accuracy: 0.9825 - val_loss: 0.1080\n",
            "Epoch 171/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9821 - loss: 0.0971 - val_accuracy: 0.9825 - val_loss: 0.1095\n",
            "Epoch 172/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9821 - loss: 0.1037 - val_accuracy: 0.9825 - val_loss: 0.1102\n",
            "Epoch 173/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9812 - loss: 0.0915 - val_accuracy: 0.9825 - val_loss: 0.1097\n",
            "Epoch 174/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9821 - loss: 0.0933 - val_accuracy: 0.9825 - val_loss: 0.1078\n",
            "Epoch 175/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9867 - loss: 0.0978 - val_accuracy: 0.9825 - val_loss: 0.1092\n",
            "Epoch 176/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9887 - loss: 0.0903 - val_accuracy: 0.9825 - val_loss: 0.1096\n",
            "Epoch 177/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9812 - loss: 0.0899 - val_accuracy: 0.9825 - val_loss: 0.1117\n",
            "Epoch 178/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9802 - loss: 0.0984 - val_accuracy: 0.9825 - val_loss: 0.1106\n",
            "Epoch 179/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9811 - loss: 0.0941 - val_accuracy: 0.9737 - val_loss: 0.1092\n",
            "Epoch 180/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9783 - loss: 0.0950 - val_accuracy: 0.9825 - val_loss: 0.1082\n",
            "Epoch 181/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9821 - loss: 0.0990 - val_accuracy: 0.9825 - val_loss: 0.1090\n",
            "Epoch 182/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9821 - loss: 0.0937 - val_accuracy: 0.9825 - val_loss: 0.1093\n",
            "Epoch 183/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9812 - loss: 0.0831 - val_accuracy: 0.9825 - val_loss: 0.1093\n",
            "Epoch 184/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9791 - loss: 0.1035 - val_accuracy: 0.9825 - val_loss: 0.1083\n",
            "Epoch 185/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9812 - loss: 0.0997 - val_accuracy: 0.9737 - val_loss: 0.1087\n",
            "Epoch 186/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9817 - loss: 0.0865 - val_accuracy: 0.9825 - val_loss: 0.1101\n",
            "Epoch 187/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9821 - loss: 0.0928 - val_accuracy: 0.9825 - val_loss: 0.1114\n",
            "Epoch 188/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9878 - loss: 0.0879 - val_accuracy: 0.9825 - val_loss: 0.1091\n",
            "Epoch 189/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9874 - loss: 0.0913 - val_accuracy: 0.9825 - val_loss: 0.1061\n",
            "Epoch 190/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9812 - loss: 0.0964 - val_accuracy: 0.9825 - val_loss: 0.1075\n",
            "Epoch 191/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9747 - loss: 0.0916 - val_accuracy: 0.9737 - val_loss: 0.1086\n",
            "Epoch 192/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9812 - loss: 0.0969 - val_accuracy: 0.9825 - val_loss: 0.1086\n",
            "Epoch 193/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9808 - loss: 0.0893 - val_accuracy: 0.9825 - val_loss: 0.1090\n",
            "Epoch 194/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9934 - loss: 0.0792 - val_accuracy: 0.9825 - val_loss: 0.1087\n",
            "Epoch 195/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9783 - loss: 0.1043 - val_accuracy: 0.9825 - val_loss: 0.1100\n",
            "Epoch 196/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9821 - loss: 0.0904 - val_accuracy: 0.9825 - val_loss: 0.1107\n",
            "Epoch 197/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9786 - loss: 0.0919 - val_accuracy: 0.9825 - val_loss: 0.1099\n",
            "Epoch 198/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9817 - loss: 0.0953 - val_accuracy: 0.9825 - val_loss: 0.1090\n",
            "Epoch 199/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9821 - loss: 0.0959 - val_accuracy: 0.9825 - val_loss: 0.1099\n",
            "Epoch 200/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9874 - loss: 0.0865 - val_accuracy: 0.9825 - val_loss: 0.1095\n",
            "Epoch 201/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9887 - loss: 0.0966 - val_accuracy: 0.9825 - val_loss: 0.1071\n",
            "Epoch 202/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9821 - loss: 0.0870 - val_accuracy: 0.9825 - val_loss: 0.1067\n",
            "Epoch 203/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9812 - loss: 0.0993 - val_accuracy: 0.9737 - val_loss: 0.1071\n",
            "Epoch 204/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9800 - loss: 0.0959 - val_accuracy: 0.9825 - val_loss: 0.1064\n",
            "Epoch 205/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9821 - loss: 0.1005 - val_accuracy: 0.9825 - val_loss: 0.1077\n",
            "Epoch 206/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9874 - loss: 0.0889 - val_accuracy: 0.9825 - val_loss: 0.1079\n",
            "Epoch 207/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9887 - loss: 0.0889 - val_accuracy: 0.9825 - val_loss: 0.1094\n",
            "Epoch 208/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9867 - loss: 0.0875 - val_accuracy: 0.9825 - val_loss: 0.1087\n",
            "Epoch 209/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9821 - loss: 0.0895 - val_accuracy: 0.9825 - val_loss: 0.1075\n",
            "Epoch 210/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9874 - loss: 0.0790 - val_accuracy: 0.9825 - val_loss: 0.1072\n",
            "Epoch 211/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9813 - loss: 0.0926 - val_accuracy: 0.9825 - val_loss: 0.1082\n",
            "Epoch 212/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9821 - loss: 0.0838 - val_accuracy: 0.9825 - val_loss: 0.1087\n",
            "Epoch 213/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9790 - loss: 0.0945 - val_accuracy: 0.9825 - val_loss: 0.1090\n",
            "Epoch 214/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9803 - loss: 0.0941 - val_accuracy: 0.9825 - val_loss: 0.1082\n",
            "Epoch 215/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9817 - loss: 0.0921 - val_accuracy: 0.9825 - val_loss: 0.1093\n",
            "Epoch 216/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9812 - loss: 0.0872 - val_accuracy: 0.9825 - val_loss: 0.1104\n",
            "Epoch 217/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9796 - loss: 0.0909 - val_accuracy: 0.9825 - val_loss: 0.1086\n",
            "Epoch 218/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9821 - loss: 0.0841 - val_accuracy: 0.9825 - val_loss: 0.1078\n",
            "Epoch 219/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9784 - loss: 0.0879 - val_accuracy: 0.9825 - val_loss: 0.1068\n",
            "Epoch 220/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9745 - loss: 0.0922 - val_accuracy: 0.9737 - val_loss: 0.1096\n",
            "Epoch 221/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9821 - loss: 0.0895 - val_accuracy: 0.9825 - val_loss: 0.1092\n",
            "Epoch 222/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9821 - loss: 0.0961 - val_accuracy: 0.9825 - val_loss: 0.1094\n",
            "Epoch 223/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9887 - loss: 0.0853 - val_accuracy: 0.9825 - val_loss: 0.1084\n",
            "Epoch 224/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9934 - loss: 0.0855 - val_accuracy: 0.9825 - val_loss: 0.1081\n",
            "Epoch 225/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9774 - loss: 0.0896 - val_accuracy: 0.9825 - val_loss: 0.1080\n",
            "Epoch 226/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9887 - loss: 0.0901 - val_accuracy: 0.9825 - val_loss: 0.1075\n",
            "Epoch 227/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9878 - loss: 0.0862 - val_accuracy: 0.9825 - val_loss: 0.1079\n",
            "Epoch 228/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9821 - loss: 0.0801 - val_accuracy: 0.9825 - val_loss: 0.1078\n",
            "Epoch 229/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9887 - loss: 0.0840 - val_accuracy: 0.9825 - val_loss: 0.1073\n",
            "Epoch 230/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9808 - loss: 0.0851 - val_accuracy: 0.9825 - val_loss: 0.1076\n",
            "Epoch 231/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9812 - loss: 0.0855 - val_accuracy: 0.9825 - val_loss: 0.1101\n",
            "Epoch 232/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9755 - loss: 0.0933 - val_accuracy: 0.9825 - val_loss: 0.1081\n",
            "Epoch 233/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9821 - loss: 0.0929 - val_accuracy: 0.9737 - val_loss: 0.1084\n",
            "Epoch 234/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9887 - loss: 0.0796 - val_accuracy: 0.9825 - val_loss: 0.1081\n",
            "Epoch 235/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9803 - loss: 0.0954 - val_accuracy: 0.9737 - val_loss: 0.1074\n",
            "Epoch 236/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9821 - loss: 0.0856 - val_accuracy: 0.9825 - val_loss: 0.1081\n",
            "Epoch 237/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9804 - loss: 0.0897 - val_accuracy: 0.9737 - val_loss: 0.1093\n",
            "Epoch 238/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9804 - loss: 0.0849 - val_accuracy: 0.9825 - val_loss: 0.1070\n",
            "Epoch 239/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9821 - loss: 0.0847 - val_accuracy: 0.9825 - val_loss: 0.1075\n",
            "Epoch 240/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9790 - loss: 0.0852 - val_accuracy: 0.9825 - val_loss: 0.1073\n",
            "Epoch 241/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9821 - loss: 0.0823 - val_accuracy: 0.9737 - val_loss: 0.1061\n",
            "Epoch 242/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9821 - loss: 0.0794 - val_accuracy: 0.9737 - val_loss: 0.1059\n",
            "Epoch 243/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9821 - loss: 0.0842 - val_accuracy: 0.9737 - val_loss: 0.1073\n",
            "Epoch 244/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9801 - loss: 0.0844 - val_accuracy: 0.9825 - val_loss: 0.1086\n",
            "Epoch 245/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9804 - loss: 0.0879 - val_accuracy: 0.9825 - val_loss: 0.1098\n",
            "Epoch 246/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9813 - loss: 0.0850 - val_accuracy: 0.9825 - val_loss: 0.1080\n",
            "Epoch 247/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9821 - loss: 0.0860 - val_accuracy: 0.9825 - val_loss: 0.1071\n",
            "Epoch 248/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9784 - loss: 0.0904 - val_accuracy: 0.9737 - val_loss: 0.1059\n",
            "Epoch 249/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9808 - loss: 0.0907 - val_accuracy: 0.9737 - val_loss: 0.1058\n",
            "Epoch 250/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9821 - loss: 0.0846 - val_accuracy: 0.9825 - val_loss: 0.1056\n",
            "Epoch 251/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9808 - loss: 0.0928 - val_accuracy: 0.9737 - val_loss: 0.1075\n",
            "Epoch 252/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9812 - loss: 0.0866 - val_accuracy: 0.9825 - val_loss: 0.1068\n",
            "Epoch 253/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9821 - loss: 0.0855 - val_accuracy: 0.9825 - val_loss: 0.1063\n",
            "Epoch 254/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9821 - loss: 0.0867 - val_accuracy: 0.9737 - val_loss: 0.1082\n",
            "Epoch 255/255\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9876 - loss: 0.0822 - val_accuracy: 0.9825 - val_loss: 0.1055\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train, y_train, epochs=255, batch_size=32, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "wLKRLydIv7ve",
        "outputId": "93101528-74ab-40f5-e2c3-29c1ea7afe42"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training Performance')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🔒 Regularization\n",
        "Goal: Prevent overfitting (when your model memorizes training data instead of generalizing).\n",
        "\n",
        "How: Adds a penalty to the loss function to discourage complex models.\n",
        "\n",
        "## 🧮 Types:\n",
        "1. L1 (Lasso) – Adds absolute value of weights:\n",
        "Loss = original_loss + λ * Σ|weights|\n",
        "\n",
        "Can make some weights exactly zero (feature selection).\n",
        "\n",
        "2. L2 (Ridge) – Adds square of weights:\n",
        "Loss = original_loss + λ * Σ(weights²)\n",
        "\n",
        "Penalizes large weights, keeps all features, makes weights smaller.\n",
        "\n",
        "3. Elastic Net – Mix of L1 and L2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ⚖️ Batch Normalization\n",
        "        is a technique to normalize the inputs to each layer in a neural network during training.\n",
        "Goal: Speed up training and make it more stable.\n",
        "How: Normalizes the output of a layer before activation:\n",
        "* Makes outputs have mean ~0 and std ~1.\n",
        "* Adds trainable parameters: scale and shift.\n",
        "\n",
        "## 📈 Benefits:\n",
        "* Stabilize and speed up training\n",
        "* Reduce sensitivity to weight initialization\n",
        "* Often allows for higher learning rates\n",
        "* Acts like a regularizer, sometimes reducing need for dropout\n",
        "\n",
        "## 🧪 Why Do We Need It?\n",
        "* During training, as each layer updates, the distribution of inputs to subsequent layers keeps shifting — this is known as the internal covariate shift.\n",
        "* This can slow training and make it unstable.\n",
        "* BatchNorm reduces this shift by keeping inputs to each layer normalized, so layers don't need to constantly readjust."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# validation_split vs validation_data\n",
        "\n",
        "## 1. validation_data:\n",
        "You explicitly provide validation inputs and labels.\n",
        "\n",
        "* Syntax: model.fit(X_train, y_train, validation_data=(X_val, y_val))\n",
        "\n",
        "* You manually prepare the validation set\n",
        "* Works with arrays, datasets, or generators\n",
        "\n",
        "## 2. validation_split:\n",
        "Automatically splits off a portion of the training data for validation.\n",
        "\n",
        "Syntax: model.fit(X, y, validation_split=0.2)\n",
        "\n",
        "* Uses 20% of X and y for validation.\n",
        "* Only works if X and y are NumPy arrays or tensors.\n",
        "* Split is done after shuffling, unless shuffle=False.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
